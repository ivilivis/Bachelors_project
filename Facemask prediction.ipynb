{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "os.environ[\"PLAIDML_EXPERIMENTAL\"] = \"1\"\n",
    "os.environ[\"PLAIDML_DEVICE_IDS\"] = \"opencl_nvidia_nvidia_geforce_rtx_3060_ti.0\" #Edit for correct GPU\n",
    "from keras import backend as K\n",
    "import random\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths for training and testing directories\n",
    "train_dir = r'D:\\Datasets FAces\\Dataset_Final\\Training/' #Set own path\n",
    "train_paths = []\n",
    "for label in os.listdir(train_dir):\n",
    "    for file in os.listdir(train_dir+label):\n",
    "        train_paths.append(train_dir+label+'/'+file)\n",
    "random.shuffle(train_paths)\n",
    "\n",
    "test_dir = r'D:\\Datasets FAces\\Dataset_Final\\test_test/' #Set own path\n",
    "test_paths = []\n",
    "for label in os.listdir(test_dir):\n",
    "    for file in os.listdir(test_dir+label):\n",
    "        test_paths.append(test_dir+label+'/'+file)\n",
    "random.shuffle(test_paths)\n",
    "\n",
    "# Predict on new data:\n",
    "\n",
    "predict_dir = r'D:/Datasets FAces/Dataset_Final/test_final/' #Set own path\n",
    "predict_paths = []\n",
    "for label in os.listdir(predict_dir):\n",
    "    for file in os.listdir(predict_dir+label):\n",
    "        predict_paths.append(predict_dir+label+'/'+file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and list labels\n",
    "labels = os.listdir(train_dir)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5463da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open images in directory\n",
    "def open_images(paths):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=(128,128))\n",
    "        input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "        input_arr = np.array(input_arr)/255.0 # Convert single image to a batch\n",
    "        images.append(input_arr)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from paths:\n",
    "def get_labels(paths):\n",
    "    label = []\n",
    "    for path in paths:\n",
    "        path = path.split('/')[-2]\n",
    "        label.append(labels.index(path))\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = open_images(test_paths)\n",
    "test_labels = get_labels(test_paths)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff354f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = open_images(train_paths)\n",
    "train_labels = get_labels(train_paths)\n",
    "train_labels = to_categorical(train_labels)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f884c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) # specifying the overall grid size\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(train_paths[i].split('/')[-2]) #Grabs the label from path\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=32\n",
    "batch_size=128\n",
    "#epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_images\n",
    "targets = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Validation Dataset\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(inputs, targets, train_size=0.9, test_size=0.1, random_state=42)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, train_size=0.78, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa25c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of training samples\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                                   vertical_flip=True)\n",
    "it = train_datagen.flow(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e827244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment validation set\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                                   vertical_flip=True)\n",
    "val_it = val_datagen.flow(Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7895e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment test set\n",
    "test_datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                                   vertical_flip=True)\n",
    "test_it = val_datagen.flow(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396808ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "steps_per_epoch = math.ceil(len(Xtrain)/32) #Recommended size. 32 is the inital batch size\n",
    "#steps_per_epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply early stopping to find optimal number of epochs\n",
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",\n",
    "                                        mode =\"min\", patience = 10,\n",
    "                                        restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature extractors from ResNet50 pretrained network\n",
    "\n",
    "#restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(128,128,3))\n",
    "#output = restnet.layers[-1].output\n",
    "#output = keras.layers.Flatten()(output)\n",
    "#restnet = Model(restnet.input, output=output)\n",
    "#for layer in restnet.layers:\n",
    "#    layer.trainable = False\n",
    "#restnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature extractors from VGG16/VGG19 pretrained network\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "#from keras.models import Model\n",
    "\n",
    "# load model\n",
    "#VGG = VGG19(include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d643dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(it):\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    # ResNet Model\n",
    "    #model.add(restnet)\n",
    "    #model.add(Dense(512, activation='relu', input_dim=(128,128,3)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    #################################################################\n",
    "    # VGG Model\n",
    "    #model.add(VGG)\n",
    "    #model.add(Dense(512, activation='relu', input_dim=(128,128,3)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    #################################################################\n",
    "    # Plain CNN Model as reference\n",
    "    model.add(Conv2D(32, (3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(128,128,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten()) # Uncomment for VGG16, comment for ResNet50\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    #model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              #optimizer=optimizers.RMSprop(lr=2e-5), # Alternative optimizer\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "\n",
    "    history = model.fit_generator(\n",
    "    it, epochs=300, verbose=2,\n",
    "    callbacks=[earlystopping], validation_data=(val_it), shuffle=True,\n",
    "    class_weight=None,steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=None,\n",
    "    max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate_generator(test_it, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to directory\n",
    "model.save('Keras CNN Model') # Edit to own liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy and loss\n",
    "score = model.evaluate_generator(test_it, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf38274",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "y_labels = []\n",
    "for i in range(0,len(test_paths)):\n",
    "    images = open_images([test_paths[i]])\n",
    "    predict = model.predict(images)[0]\n",
    "    predict = np.argmax(predict)\n",
    "    predict = labels[predict]\n",
    "    y_predicted.append(predict)\n",
    "    label = test_paths[i].split('/')[-2]\n",
    "    y_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06686c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_labels, y_predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45cf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Facemask\n",
    "for i in range(0,len(predict_paths)):\n",
    "    images = open_images([predict_paths[i]])\n",
    "    predicted = model.predict(images)[0]\n",
    "    predicted = np.argmax(predicted)\n",
    "    predicted = labels[predicted]\n",
    "    label = predict_paths[i].split('/')[-2]\n",
    "    print(predict_paths[i],'Predicted:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2792fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Facemask\n",
    "predict_dir = r'D:/Datasets FAces/test/' #Set own path\n",
    "predict_paths = []\n",
    "for label in os.listdir(predict_dir):\n",
    "    for file in os.listdir(predict_dir+label):\n",
    "        predict_paths.append(predict_dir+label+'/'+file)\n",
    "\n",
    "for i in range(0,len(predict_paths)):\n",
    "    images = open_images([predict_paths[i]])\n",
    "    predicted = model.predict(images)[0]\n",
    "    predicted = np.argmax(predicted)\n",
    "    predicted = labels[predicted]\n",
    "    label = predict_paths[i].split('/')[-2]\n",
    "    print(predict_paths[i],'Predicted:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfd487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
